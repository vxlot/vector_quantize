#### uv

##### æ–°å»ºç¯å¢ƒ

1. è¿›å…¥æ–°å»ºçš„ç¯å¢ƒæ–‡ä»¶å¤¹

   ```bash
   cd /home/110/u110003/uv_env/default
   ```

2. é…ç½® `pyproject.toml` æ–‡ä»¶ 

   name = "default" è¦å’Œæ–‡ä»¶å¤¹åå­—ä¸€è‡´

   dependencies åˆ—è¡¨ä¸­æ‰‹åŠ¨æ·»åŠ ä¾èµ–

   ä¿æŒ torch å’Œ cuda ç‰ˆæœ¬é€‚é…

   ```toml
   [build-system]
   requires = ["setuptools>=68", "wheel"]
   build-backend = "setuptools.build_meta"
   
   [project]
   name = "default"
   version = "0.0.1"
   description = "description of your program"
   requires-python = ">=3.8,<3.9"
   
   dependencies = [
     "torch==1.13.1",
     "torchvision==0.14.1",
     "numpy==1.19.2",
     "albumentations~=1.0.0",
     "opencv-python>=4.2",
     "pudb==2019.2",
     "imageio==2.9.0",
     "imageio-ffmpeg==0.4.2",
     "pytorch-lightning<1.3",
     "omegaconf==2.0.0",
     "test-tube>=0.7.5",
     "streamlit>=0.73.1",
     "einops==0.3.0",
     "more-itertools>=8.0.0",
     "transformers==4.3.1",
   ]
   
   
   [tool.uv]
   index-url = "https://download.pytorch.org/whl/cu118"
   extra-index-url = ["https://pypi.org/simple"]
   ```

3. å®‰è£…

   ```bash
   uv sync
   ```

##### æ›´æ”¹æ–°ä¾èµ–

```bash
uv add "protobuf>=4.21,<5.0"
uv add --editable /home/110/u110003/code/OptVQ  # pip install .
uv add --editable /home/110/u110003/code/1007/non_neg[dali,umap,h5]  # pip install .[dali,umap,h5]
uv add /home/110/u110003/uv_env/pkgs/taming-transformers
uv add git+https://github.com/mit-han-lab/efficientvit.git
uv remove umap
```

å…³äºå¯ç¼–è¾‘å®‰è£…çš„setup

```py
install_requires=[
    "torch==1.10.0+cu113",  # ä¸è¦åœ¨setupé‡Œå†™æ­»ï¼Œåœ¨ pyproject.toml é‡ŒæŒ‡å®š index-url = "https://download.pytorch.org/whl/cu113"
    "torchvision==0.11.1",
    ...
],
dependency_links=["https://developer.download.nvidia.com/compute/redist"],
```

##### æ¿€æ´»ç¯å¢ƒ

```bash
source /home/110/u110003/uv_env/default/.venv/bin/activate
deactivate
```

#### git

##### github push

å…ˆç¡®è®¤æ˜¯å¦æœ‰`git`ï¼Œå¹¶åœ¨`gitee`æ–°å»ºä»“åº“ï¼Œè¿›å…¥ä»“åº“çš„ç®¡ç†é€‰é¡¹ï¼Œè½¬ç§»ä»“åº“ï¼Œè½¬ç§»åˆ°æˆ‘æ‰€åœ¨æœ‰æƒå‘åˆ›å»ºä»“åº“çš„ä¼ä¸šã€‚

```bash
git --version
name:13606398519 pwd:weixiaolu617@gmail
```

å¦‚æœé¡¹ç›®ä¸æ˜¯cloneæƒ³æ¥çš„éœ€è¦åˆå§‹åŒ–ä¸€ä¸‹

```bash
git init
```

åˆå§‹åŒ–çš„ç”¨addæ–°å»ºåˆ†æ”¯ï¼Œæœ‰gitçš„ç”¨set-url

```bash
git remote add/set-url origin https://gitee.com/dailongquan-cs/simvq-two-linear.git
git checkout -b two-linear-div
```

ä½ å¯èƒ½ä¼šç”¨åˆ°ï¼š

```bash
rm .git/index.lock
ps aux | grep git
pkill -9 git
```

é…ç½®

```bash
git config --global user.email "13606398519@163.com"
git config --global user.name "vxlot"
```

åœ¨vscodeé‡Œç‚¹åŠ å·ä¹‹åæäº¤

```bash
git push
git push --set-upstream origin master
```

å¦‚æœéœ€è¦å±è”½å¤§æ–‡ä»¶ï¼Œåœ¨`.gitignore`é‡Œå†™æ–‡ä»¶è·¯å¾„

```git
vq_log
*.pyc
configs/recons
configs/source
compare
```

##### download pkgs

```bash
# å¯ç¼–è¾‘å®‰è£…æŒ‡å®šç‰ˆæœ¬çš„åŒ…
git clone https://github.com/rwightman/pytorch-image-models
cd pytorch-image-models
git checkout c2ba229d995c33aaaf20e00a5686b4dc857044be
pip install -e .
```

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š
 ğŸ‘‰ https://github.com/rwightman/pytorch-image-models/tree/c2ba229d995c33aaaf20e00a5686b4dc857044be

ä¸‹è½½å¾—åˆ°ä¸€ä¸ªå‹ç¼©åŒ…ï¼špytorch-image-models-c2ba229.zip

```bash
unzip pytorch-image-models-c2ba229.zip
tar -xvf pytorch-image-models-c2ba229.zip
cd pytorch-image-models-c2ba229d995c33aaaf20e00a5686b4dc857044be
pip install -e .
```

æœ€åéªŒè¯ä¸€ä¸‹ï¼š`python -c "import timm; print(timm.__version__)"`

#### bash

è½¯é“¾æ¥

```bash
ln -s /home/110/u110003/ckpt/dq/64x64_diffusion.pt /home/110/u110003/code/dq/models/64x64_diffusion.pt
```

hf

```python
export HF_ENDPOINT=https://hf-mirror.com
export HF_HOME="/home/110/u110003/hf_download"
export PYTHONPATH=$(pwd):$PYTHONPATH

ssh 10.10.20.9
source /home/110/u110003/uv_env/muddit/.venv/bin/activate
python -c 'import torch;from diffusers import FluxControlNetModel;FluxControlNetModel.from_pretrained("Xlabs-AI/flux-controlnet-hed-diffusers",torch_dtype=torch.bfloat16,use_safetensors=True)'

srun --gpus=1 --partition=debug-A10-01 --ntasks-per-node=1 python -c 'from diffusers import StableDiffusionPipeline;pipe = StableDiffusionPipeline.from_pretrained("MeissonFlow/Meissonic", trust_remote_code=True)'
python -c 'from diffusers import DiffusionPipeline;pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0")'
python -c "from torchvision.datasets import CIFAR100; CIFAR100(root='/home/110/u110003/code/1007/non_neg/data', train=True, download=True)"

python -c "import torch;print(torch.cuda.is_available());print(torch.version.cuda);print(torch.version.git_version);print(torch.backends.cudnn.version())"
ssh-keygen -R 10.10.20.2
```

#### debug

launch.json

```json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "eval/generate",
            "type": "debugpy",
            "request": "launch",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",  // å†³å®šç›¸å¯¹è·¯å¾„æ–‡ä»¶çš„èµ·ç‚¹ç›®å½•
            "python": "/home/110/u110003/uv_env/seed/.venv/bin/python",
            "program": "generate_embeds.py",  // reconstruct_image.py
            "args": [
                "--config_file=configs/mnist_train_dcae.yaml",
                "--ckpt_path=logs/ckpt/epoch=1-step=17000.ckpt"
            ],
            "env": {
                // "HF_ENDPOINT": "https://hf-mirror.com",
                // "HF_HOME": "/home/110/u110003/hf_download",
                // "CUDA_VISIBLE_DEVICES": "0",
                "PYTHONPATH": "${workspaceFolder}:$PYTHONPATH",  // Python å»å“ªé‡Œæ‰¾æ¨¡å—ï¼Œå½±å“ import
            },
        },
    ]
}
```

#### slurm

```bash
#!/bin/bash
#SBATCH --job-name=abc                                #ä»»åŠ¡åç§°
#SBATCH --output=/home/110/u110003/slurm/nips/abc/out.log  #è¾“å‡ºæ–‡ä»¶
#SBATCH --error=/home/110/u110003/slurm/nips/abc/err.log  #é”™è¯¯æ—¥å¿—æ–‡ä»¶
#SBATCH --nodes=1                                         #ç”³è¯·èŠ‚ç‚¹æ•°é‡
#SBATCH --partition=debug-4090-01              
#SBATCH --ntasks-per-node=4                               #ä¸ç”¨æ”¹
#SBATCH --gres=gpu:4                                      #æ¯ä¸ªèŠ‚ç‚¹çš„GPU
#SBATCH --cpus-per-task=8                                 #æ¯ä¸ªèŠ‚ç‚¹çš„CPU
#SBATCH --chdir=/home/110/u110003/code/nips/DiffusionDPO      #ä»»åŠ¡çš„å·¥ä½œç›®å½•

echo "SLURM_JOB_NODELIST: $SLURM_JOB_NODELIST"
nodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )
nodes_array=($nodes)
head_node=${nodes_array[0]}
head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-address)

echo Node IP: $head_node_ip
export LOGLEVEL=INFO
export TORCHELASTIC_ENABLE_FILE_TIMER=1

# ä»¥ä¸‹å†™å…·ä½“çš„ä»»åŠ¡
export HF_DATASETS_OFFLINE=1
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export DATASET_NAME="yuvalkirstain/pickapic_v2"

# Effective BS will be (N_GPU * train_batch_size * gradient_accumulation_steps)
# Paper used 2048. Training takes ~24 hours / 2000 steps

srun --nodes=1 --ntasks-per-node=4 --gres=gpu:4 --cpus-per-task=8 \
    accelerate launch --main_process_port 29415 --mixed_precision="fp16" train.py \
      --pretrained_model_name_or_path=$MODEL_NAME \
      --dataset_name=$DATASET_NAME \
      --train_batch_size=1 \
      --dataloader_num_workers=4 \
      --gradient_accumulation_steps=128 \
      --max_train_steps=2000 \
      --lr_scheduler="constant_with_warmup" --lr_warmup_steps=500 \
      --learning_rate=1e-8 --scale_lr \
      --cache_dir="/home/common/Pick-a-Pic/picapic-v2/" \
      --checkpointing_steps 500 \
      --beta_dpo 5000 \
      --output_dir="./tmp-sd15"
```



```bash
source /home/110/u110003/uv_env/ibq/.venv/bin/activate
sbatch /home/110/u110003/slurm/iclr/train_3090_rqvae.slurm
scancel 319
srun  --gpus=26 gpustat --partition=gpu
squeue --user u110003

srun --gpus=16 --partition=debug-A10-01 --ntasks-per-node=8 python main.py fit --config configs/IBQ/gpu/imagenet_ibqgan_1024.yaml
srun --gpus=6 --partition=gpu-TITAN-01 --ntasks-per-node=8 python main.py fit --config configs/IBQ/gpu/imagenet_ibqgan_1024.yaml

squeue
ssh-keygen -R gpu-node-02
```



#### py tools

##### unpack_npz.py

```python
import numpy as np
from PIL import Image
import os
import argparse


def unpack_npz(npz_path, out_dir, limit=None):
    # è¯»å– npz æ–‡ä»¶
    data = np.load(npz_path)
    images = data["arr"]
    labels = data["label_arr"]

    print("images shape:", images.shape)   # (N, H, W, 3)
    print("labels shape:", labels.shape)   # (N,)

    os.makedirs(out_dir, exist_ok=True)

    num_images = len(images) if limit is None else min(limit, len(images))
    for i in range(num_images):
        img = Image.fromarray(images[i])
        filename = f"{i:05d}_label{labels[i]}.png"
        img.save(os.path.join(out_dir, filename))

    print(f"âœ… å·²ä¿å­˜ {num_images} å¼ å›¾ç‰‡åˆ° {out_dir}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--npz_path", default="/tmp/openai-2025-09-25-10-36-02-425281/samples_20x64x64x3.npz")
    parser.add_argument("--out_dir", default="./unpack")
    parser.add_argument("--limit", type=int, default=None)
    args = parser.parse_args()

    unpack_npz(args.npz_path, args.out_dir, args.limit)
```

#### py pkgs

##### torchview

```bash
uv add torchview>=0.2.7
```

usage: draw nn.Module's program

```python
from torchview import draw_graph

draw_graph(<your model>, 
                input_data=torch.randn(1, 3, 256, 256, dtype=torch.float16).cuda(), 
                save_graph=False, 
                expand_nested=True
            ).visual_graph.render("vae_graph", format="png", cleanup=True)
```

#### web tools

æ‰‹ç»˜é£æ ¼æµç¨‹å›¾ï¼šhttps://excalidraw.com/

å…¬å¼è¯†åˆ«è½¬latexï¼šhttps://simpletex.cn

emojiï¼šhttps://github.com/twitter/twemoji/blob/master/assets/svg/1f60d.svg

#### prompts

æˆ‘çš„ç›®æ ‡æ˜¯ï¼šå°†ç¬¬ä¸€ä¸ªç±» (`ImageCaptionLargeDataset`) ä¸­å¤„ç†å’Œè¿”å› **`prompt_input_ids`** çš„é€»è¾‘ï¼Œé›†æˆåˆ°æˆ‘æ­£åœ¨ä½¿ç”¨çš„ **`ImageDataset`** ç±»ä¸­ã€‚

åŠ ä¸Šå…¬å¼å’Œç¬¦å·ä»”ç»†è®²è®² å…¬å¼ä¸è¦ç•™ç€markdown$FF^\top$å°±ç»™æˆ‘å±•ç¤ºäº† æˆ‘è¦çœ‹åˆ°å…¬å¼ å°±æ˜¯ä½ æ¸²æŸ“å¥½äº†å†ç»™æˆ‘ã€‚

#### diffusion

##### ddpm

referenceï¼š https://kexue.fm/archives/9119

æ‰©æ•£æ¨¡å‹å¸Œæœ›å°†ä¸€å¼ å›¾ç‰‡ $x_0$ ä¸æ–­åœ°åŠ å™ªå£°æœ€åå˜æˆ $x_T \sim \mathcal{N}(\mathbf{0},\boldsymbol{I})$ å­¦ä¹ åˆ° $x_t$ ä¸ $x_{t-1}$ çš„å…³ç³»ï¼Œä»è€Œæ¨ç†çš„æ—¶å€™é™å™ªè¿˜åŸæˆå›¾åƒã€‚

$x_t \to p(x_{t-1}|x_t)$ å¦‚æœæœ‰äº†è¿™ä¸ª**åˆ†å¸ƒ**ï¼Œå°±å¯ä»¥ä»åˆ†å¸ƒé‡Œå–ä¸€ä¸ª $x_{t-1}$ ï¼Œè®©ç»“æœæ›´åŠ çš„å…·æœ‰éšæœºæ€§ã€‚
$$
p(x_{t-1}|x_{t})=\frac{p(x_{t}|x_{t-1})p(x_{t-1})}{p(x_{t})}
$$
$p(x_t|x_{t-1})$  æ˜¯å‰å‘åŠ å™ªè¿‡ç¨‹ï¼Œæ˜¯äººä¸ºè®¾å®šçš„ï¼Œé€šè¿‡è®¾å®šå¥½çš„ $\alpha_t\beta_t$ è¡¨è¿›è¡Œè®¡ç®—ã€‚
$$
{x}_t=\sqrt{\alpha_t}{x}_{t-1}+\sqrt{\beta_t}{\varepsilon}_t,\quad\alpha_t,\beta_t\gt0\quad\alpha_t+\beta_t=1
\quad
\boldsymbol{\varepsilon}_t\sim\mathcal{N}(\mathbf{0},\boldsymbol{I})
$$
å› ä¸º $\boldsymbol{\varepsilon}_t\sim\mathcal{N}(\mathbf{0},\boldsymbol{I})$ ï¼Œæ‰€ä»¥ $\sqrt{\beta_t}\boldsymbol{\varepsilon}_t\sim\mathcal{N}(\mathbf{0},\beta_t)$ ï¼Œæœ‰
$$
p(x_{t}|x_{t-1}) \sim \mathcal{N}(\sqrt{\alpha_t}{x}_{t-1},\beta_t)
$$
å¦å¤–ä¸¤é¡¹æ¦‚ç‡å•ç‹¬æ±‚è§£éš¾ï¼Œè€ƒè™‘åŠ å…¥ $x_0$ æ¡ä»¶ï¼Œç”±äºé©¬å°”å¯å¤«æ€§è´¨ï¼Œ $p(x_{t}|x_{t-1},x_0)=p(x_{t}|x_{t-1})$ 
$$
p(x_{t-1}|x_{t},x_0)=\frac{p(x_{t}|x_{t-1})p(x_{t-1}|x_0)}{p(x_{t}|x_0)}
$$
å…³äº $p(x_{t}|x_0)$ ï¼Œæœ‰å¿«é€Ÿé‡‡æ ·xtçš„æ–¹æ³•
$$
\begin{align}
{x}_t=\sqrt{\bar{\alpha}_{t}}{x}_0+\sqrt{\bar{\beta}_{t}}\varepsilon,
\quad\bar{\alpha}_{t}={\alpha}_{t}{\alpha}_{t-1}...{\alpha}_{1}
\quad\bar{\alpha}_{t} + \bar{\beta}_{t}=1
\quad{\varepsilon}\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})
\end{align}
$$
æ‰€ä»¥æ¦‚ç‡ä¸Š
$$
p(x_{t}|x_0) \sim \mathcal{N}(\sqrt{\bar{\alpha}_{t}}{x}_0,1-\bar{\alpha}_{t})
$$
ä¸‰ä¸ªé«˜æ–¯åˆ†å¸ƒåšä¸€ä¸‹è¿ç®—å°±å¾—åˆ°æ–¹å·®å›ºå®šçš„ä¸€ä¸ªåˆ†å¸ƒï¼Œ**é—®é¢˜è½¬æ¢æˆæ±‚ $\tilde{\mu}(x_0,x_t)$ **ã€‚
$$
p(x_{t-1}|x_0,x_t) \sim \mathcal{N}(\tilde{\mu}(x_0,x_t),\tilde{\beta_t})
$$
åå‘æ±‚è§£å°±å¯ä»¥ä»åˆ†å¸ƒä¸­é‡‡æ ·ï¼š
$$
\begin{align}
{x}_{t-1}=\tilde{\mu}(x_0,x_t) + \sqrt{\tilde{\beta_t}}\varepsilon, 
\quad{\varepsilon}\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})
\end{align}
$$
æ•°å€¼ä¸Šï¼Œè¿™ä¸ªå‡å€¼çš„è¡¨è¾¾å¼ä¸ºï¼š
$$
\tilde{\mu}(x_0,x_t)=
\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}x_0 +
\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t
$$
æ­¤æ—¶ï¼Œå¦‚æœçŸ¥é“äº† $x_0, x_t$ å°±å¯ä»¥å¾—åˆ° $x_{t-1}$ çš„åˆ†å¸ƒï¼Œä»è€Œé‡‡æ ·å‡ºä¸€ä¸ª  $x_{t-1}$ã€‚ä½†æ˜¯åœ¨æ¨ç†çš„æ—¶å€™ï¼Œæˆ‘ä»¬æ²¡æœ‰ $x_0$ ï¼Œæ‰€ä»¥ä¸‹é¢éœ€è¦é‡å‚æ•°åŒ–æ¥ç”¨ $x_t$ æ±‚å‡ºä¸€ä¸ªå¯ä»¥ç”¨æ¥ä»£æ›¿çš„ $x_0$ ã€‚**æ³¨æ„åˆ°å¼ï¼ˆ1ï¼‰ï¼Œå˜æ¢å¾—åˆ°ä¸€ä¸ªå·¥å…· $x_0$ **ï¼š
$$
x_0=\frac{1}{\sqrt{\bar{\alpha}_t}}(x_t-\sqrt{1-\bar{\alpha}_t}\varepsilon)
$$
è¿™æ ·æœªçŸ¥é‡è¿›ä¸€æ­¥å®šä½åˆ° $\varepsilon$ ï¼Œæ‰€ä»¥ Unet è¾“å…¥çš„æ˜¯ $x_t$ ï¼Œé¢„æµ‹ä¸€ä¸ªå™ªéŸ³ï¼Œ**è¿™ä¸ªå™ªéŸ³æ˜¯ $t$ æ—¶åˆ»å’Œ $0$ æ—¶åˆ»ä¹‹é—´çš„å™ªéŸ³**ã€‚

å›é¡¾ä¸€ä¸‹è¿™ä¸ªè·¯å¾„ï¼Œ$p(x_{t-1}|x_{t}) \to p(x_{t-1}|x_{t},x_0) \to \tilde{\mu}(x_0,x_t) \to x_0 \to \varepsilon$ ã€‚

å¼ï¼ˆ2ï¼‰æœ€ç»ˆåŒ–ç®€ä¸ºï¼š
$$
\begin{align}
{x}_{t-1}=\frac{1}{\sqrt{\alpha_t}}x_t - \frac{\beta_t}{\sqrt{\alpha_t(1-\bar{\alpha}_t)}}\varepsilon_\theta(x_t,t) + \sqrt{\tilde{\beta_t}}\varepsilon, 
\quad{\varepsilon}\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})
\end{align}
$$
PS: å°ä¾‹å­
$$
\begin{align*}
x_{3} &= \alpha_{3} x_{2} + \beta_{3} \epsilon_{3} \\
    &= \alpha_{3}(\alpha_{2}x_{1} + \beta_{2}\epsilon_{2}) + \beta_{3} \epsilon_{3} \nonumber \\
    &= \alpha_{3}(\alpha_{2}(\alpha_{1}x_{0} + \beta_{1}\epsilon_{1}) + \beta_{2}\epsilon_{2}) + \beta_{3} \epsilon_{3} \nonumber \\
    &= (\alpha_{3}\alpha_{2}\alpha_{1})x_{0} + (\alpha_{3}\alpha_{2})\beta_{1}\epsilon_{1} + \alpha_{3}\beta_{2}\epsilon_{2} + \beta_{3} \epsilon_{3} \nonumber
\end{align*}
$$
å³è¾¹å¯ä»¥çœ‹æˆå¤šä¸ªç›¸äº’ç‹¬ç«‹çš„æ­£æ€å™ªå£°ä¹‹å’Œ

æ­£æ€åˆ†å¸ƒçš„å åŠ æ€§ï¼šå¤šä¸ªç‹¬ç«‹çš„æ­£æ€å™ªå£°ä¹‹å’Œçš„åˆ†å¸ƒï¼Œå®é™…ä¸Šæ˜¯å‡å€¼ä¸º0ã€æ–¹å·®ä¸º $S3$ çš„æ­£æ€åˆ†å¸ƒ
$$
\begin{align*}
S_3 &= \alpha_{3}^2\alpha_{2}^2\beta_{1}^2 + \alpha_{3}^2\beta_{2}^2 + \beta_{3}^2 \\
    &= \alpha_{3}^2[\alpha_{2}^2\beta_{1}^2 + \beta_{2}^2] + \beta_{3}^2 \\
    &= \alpha_{3}^2[\alpha_{2}^2(1-\alpha_{1}^2) + (1-\alpha_{2}^2)] + \beta_{3}^2 \\
    &= \alpha_{3}^2[1-\alpha_{2}^2\alpha_{1}^2] + \beta_{3}^2 \\
    &= \alpha_{3}^2[1-\alpha_{2}^2\alpha_{1}^2] + (1-\alpha_{3}^2) \\
    &= 1-\alpha_{3}^2\alpha_{2}^2\alpha_{1}^2 \\
    &= 1-\prod_{i=1}^3\alpha_i^2
\end{align*}
$$
æ‰€ä»¥æœ‰xtçš„ç®€å•è®¡ç®—æ–¹æ³•
$$
\begin{align}
\boldsymbol{x}_t=(\alpha_t\cdots\alpha_1)\boldsymbol{x}_0+\sqrt{1-(\alpha_t\cdots\alpha_1)^2}\bar{\boldsymbol{\varepsilon}}_t,\quad\bar{\boldsymbol{\varepsilon}}_t\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})
\end{align}
$$

##### cfg

ä¸ºäº†å’Œ ddpm åŒºåˆ†ï¼Œ æˆ‘ä»¬åœ¨æ¡ä»¶ç”Ÿæˆä½¿ç”¨ $\hat{p}(x_{t-1}|x_t,y)$ æ¥è¡¨ç¤ºæœ€ç»ˆç›®æ ‡ã€‚

Classifier guidance æ˜¯ä¸€ç§é‡‡æ ·æ–¹æ³•ï¼Œä»–å¸Œæœ›å¤ç”¨å·²ç»è®­ç»ƒå¥½çš„ ddpm æ¨¡å‹ï¼Œå†é¢å¤–è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ã€‚


$$
\hat{p}
$$

#### discrete(mask) diffusion



#### representation learning

The task of representation learning is to learn an encoder function $f : \mathbb{R}^d \rightarrow \mathbb{R}^k$ that extracts low-dimensional data representations $z \in \mathbb{R}^k$ *(a.k.a. features)* from inputs $x \in \mathbb{R}^d$.

Through a simple reparameterization, NCL can remarkably enhance the feature interpretability, sparsity, orthogonality, and disentanglement.

##### é‡å»ºå¼ 

**ç›®æ ‡**ï¼šé€šè¿‡â€œé‡å»ºè¾“å…¥â€æ¥è¿«ä½¿æ¨¡å‹å­¦ä¹ æœ‰ä¿¡æ¯é‡çš„è¡¨ç¤ºã€‚

**Autoencoder (AE)**ï¼šç»å…¸åšæ³•ï¼Œå‹ç¼© â†’ é‡å»ºã€‚

**å˜åˆ†è‡ªç¼–ç å™¨ (VAE)**ï¼šåœ¨ AE åŸºç¡€ä¸ŠåŠ ä¸Šæ¦‚ç‡åˆ†å¸ƒçº¦æŸï¼Œè¡¨ç¤ºæœä»æ½œåœ¨åˆ†å¸ƒã€‚

**Masked Autoencoder (MAE)** / **Masked Diffusion Models**ï¼šé®æ‰ä¸€éƒ¨åˆ†è¾“å…¥ï¼ˆåƒç´ /patch/å™ªå£°ï¼‰è®©æ¨¡å‹å»é¢„æµ‹ç¼ºå¤±éƒ¨åˆ†ï¼Œä»è€Œå­¦åˆ°å…¨å±€ç»“æ„æ„ŸçŸ¥çš„è¡¨ç¤ºã€‚

##### å¯¹æ¯”å¼/è‡ªç›‘ç£

**ç›®æ ‡**ï¼šæ‹‰è¿‘â€œæ­£æ ·æœ¬å¯¹â€è¡¨ç¤ºï¼Œæ‹‰è¿œâ€œè´Ÿæ ·æœ¬å¯¹â€ã€‚

- **SimCLR**ã€**MoCo**ã€**BYOL**ã€**SwAV**ï¼šå›¾åƒå¯¹æ¯”å­¦ä¹ çš„ä»£è¡¨ã€‚
- **CLIP**ï¼šè·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼ˆå›¾åƒ â†” æ–‡æœ¬ï¼‰ã€‚
- **SimSiam**ï¼šå»æ‰è´Ÿæ ·æœ¬ï¼Œåªåšæ­£æ ·æœ¬ä¸€è‡´æ€§ã€‚
- **å¯¹æ¯”è’¸é¦ (Distillation Contrastive)**ï¼šç”¨å¤§æ¨¡å‹ç‰¹å¾ä½œä¸ºæ•™å¸ˆä¿¡å·ã€‚

##### ç›‘ç£ / åŠç›‘ç£å¯¹é½

**ç›®æ ‡**ï¼šé€šè¿‡æ ‡ç­¾æˆ–å¼±ç›‘ç£è¿›è¡Œè¡¨å¾å¯¹é½ã€‚

- **Metric Learning / Triplet Loss**ï¼šé€šè¿‡è·ç¦»çº¦æŸå­¦ä¹ åˆ¤åˆ«è¡¨ç¤ºã€‚
- **å¤šä»»åŠ¡å­¦ä¹ **ï¼šè®©è¡¨ç¤ºæœåŠ¡äºå¤šä¸ªä»»åŠ¡ï¼Œä»è€Œæ›´é€šç”¨ã€‚
- **åŠç›‘ç£è¡¨ç¤ºå­¦ä¹ **ï¼šå°‘é‡æ ‡ç­¾ + å¤§é‡æ— æ ‡ç­¾æ•°æ®ï¼Œå…¸å‹å¦‚ FixMatchã€UDAã€‚

##### åŸºäºèšç±» / åŸå‹

**ç›®æ ‡**ï¼šé€šè¿‡èšç±»ä¸€è‡´æ€§æ¥å­¦è¡¨ç¤ºã€‚

- **DeepCluster**ï¼šå…ˆåšèšç±»ï¼ŒæŠŠèšç±»ç»“æœå½“ä¼ªæ ‡ç­¾è®­ç»ƒç½‘ç»œã€‚
- **SwAV**ï¼šåŒæ—¶å­¦ä¹ èšç±»ä¸­å¿ƒå’Œå¯¹æ¯”è¡¨ç¤ºã€‚
- **ProtoNets**ï¼ˆfew-shotï¼‰ï¼šåŸºäºç±»åŸå‹å‘é‡æ¥å¯¹é½è¡¨ç¤ºã€‚

##### ç”Ÿæˆå¼

**ç›®æ ‡**ï¼šé€šè¿‡ç”Ÿæˆå»ºæ¨¡å­¦åˆ°è¡¨ç¤ºã€‚

- **ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GANs)**ï¼šåˆ¤åˆ«å™¨å’Œç”Ÿæˆå™¨å¯¹æŠ—ï¼Œåˆ¤åˆ«å™¨çš„ç‰¹å¾å¯ä»¥ä½œä¸ºè¡¨ç¤ºã€‚
- **æ‰©æ•£æ¨¡å‹ (Diffusion Models)**ï¼šå­¦ä¹ å»å™ªçš„è¿‡ç¨‹ï¼Œå…¶éšç©ºé—´ç‰¹å¾å¯ä»¥å½“ä½œè¡¨å¾ã€‚
- **Flow-based Models**ï¼ˆæ­£è§„åŒ–æµï¼‰ï¼šå­¦ä¹ å¯é€†çš„å˜æ¢ï¼Œéšå˜é‡å³ä¸ºè¡¨ç¤ºã€‚





lipman_flow_2023

liu_flow_2023

#### USç­¾è¯

https://ceac.state.gov/genniv/

Application ID: AA00F1TQGF  **AA00F30XCR**



Inspired by how large language models are fine-tuned with human feedback, diffusion models have recently adopted similar preference alignment strategies. However, existing approaches like Diffusion-DPO still rely on an imperfect SFT model, which may limit their ability to fully capture human preferences.

https://github.com/twitter/twemoji/blob/master/assets/svg/1f60d.svg









welcome everyone.

i am excited to present our reasearch on ...

first, we breifly show
